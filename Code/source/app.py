"""
ğŸ¥ Polip Segmentasyon Web ArayÃ¼zÃ¼
Kolonoskopi gÃ¶rÃ¼ntÃ¼lerinden polip tespiti yapan UNet++ modeli iÃ§in Gradio arayÃ¼zÃ¼
"""

import gradio as gr
import numpy as np
import torch
import cv2
import yaml
from PIL import Image
import albumentations as A

from ML_Pipeline.network import UNetPP


# KonfigÃ¼rasyon yÃ¼kle
with open("config.yaml") as f:
    config = yaml.safe_load(f)

MODEL_PATH = config["model_path"]
IM_WIDTH = config["im_width"]
IM_HEIGHT = config["im_height"]

# Transform tanÄ±mla
transform = A.Compose([
    A.Resize(256, 256),
    A.Normalize(),
])


def load_model():
    """EÄŸitilmiÅŸ modeli yÃ¼kle"""
    model = UNetPP(1, 3, deep_supervision=True)
    
    if not torch.cuda.is_available():
        model.load_state_dict(torch.load(MODEL_PATH, map_location='cpu'))
    else:
        model.load_state_dict(torch.load(MODEL_PATH))
        model.cuda()
    
    model.eval()
    return model


# Global model yÃ¼kle
try:
    model = load_model()
    model_loaded = True
except Exception as e:
    model_loaded = False
    model_error = str(e)


def predict(image):
    """GÃ¶rÃ¼ntÃ¼den polip segmentasyonu yap"""
    
    if not model_loaded:
        return None, f"âŒ Model yÃ¼klenemedi: {model_error}"
    
    if image is None:
        return None, "âš ï¸ LÃ¼tfen bir gÃ¶rÃ¼ntÃ¼ yÃ¼kleyin"
    
    try:
        # PIL Image'Ä± numpy array'e Ã§evir
        if isinstance(image, Image.Image):
            image_np = np.array(image)
        else:
            image_np = image
        
        # Orijinal boyutu kaydet
        original_h, original_w = image_np.shape[:2]
        
        # Transform uygula
        transformed = transform(image=image_np)
        img = transformed["image"]
        
        # Model iÃ§in hazÄ±rla
        img = img.astype('float32') / 255
        img = img.transpose(2, 0, 1)  # HWC -> CHW
        img = np.expand_dims(img, 0)  # Batch dimension ekle
        img_tensor = torch.from_numpy(img)
        
        # GPU varsa kullan
        if torch.cuda.is_available():
            img_tensor = img_tensor.cuda()
        
        # Tahmin yap
        with torch.no_grad():
            output = model(img_tensor)
            mask = output[-1]  # Deep supervision'dan son Ã§Ä±ktÄ±
        
        # Maskeyi iÅŸle
        mask = mask.detach().cpu().numpy()
        mask = np.squeeze(mask)  # Batch ve channel dimension'larÄ± kaldÄ±r
        
        # Binary maskeye Ã§evir
        mask_binary = np.zeros_like(mask)
        mask_binary[mask > -2.5] = 255
        mask_binary[mask <= -2.5] = 0
        
        # Orijinal boyuta dÃ¶ndÃ¼r
        mask_resized = cv2.resize(mask_binary, (original_w, original_h))
        
        # Overlay oluÅŸtur (orijinal gÃ¶rÃ¼ntÃ¼ + maske)
        overlay = image_np.copy()
        mask_colored = np.zeros_like(overlay)
        mask_colored[:, :, 1] = mask_resized  # YeÅŸil kanal
        
        # Blend
        alpha = 0.4
        overlay = cv2.addWeighted(overlay, 1, mask_colored, alpha, 0)
        
        return overlay, "âœ… Segmentasyon baÅŸarÄ±lÄ±!"
        
    except Exception as e:
        return None, f"âŒ Hata: {str(e)}"


# Gradio ArayÃ¼zÃ¼
with gr.Blocks(
    title="ğŸ¥ Polip Segmentasyon",
    theme=gr.themes.Soft(
        primary_hue="teal",
        secondary_hue="emerald",
    )
) as demo:
    
    gr.Markdown("""
    # ğŸ¥ Polip Segmentasyon Sistemi
    
    Bu araÃ§, kolonoskopi gÃ¶rÃ¼ntÃ¼lerinden **polipleri otomatik olarak tespit** eder.
    
    **NasÄ±l kullanÄ±lÄ±r:**
    1. Kolonoskopi gÃ¶rÃ¼ntÃ¼sÃ¼ yÃ¼kleyin
    2. "Analiz Et" butonuna tÄ±klayÄ±n
    3. Tespit edilen polipler yeÅŸil renkte iÅŸaretlenir
    
    ---
    """)
    
    with gr.Row():
        with gr.Column():
            input_image = gr.Image(
                label="ğŸ“· Kolonoskopi GÃ¶rÃ¼ntÃ¼sÃ¼",
                type="pil",
                height=350
            )
            
            analyze_btn = gr.Button(
                "ğŸ” Analiz Et",
                variant="primary",
                size="lg"
            )
            
        with gr.Column():
            output_image = gr.Image(
                label="ğŸ¯ Segmentasyon Sonucu",
                height=350
            )
            status_text = gr.Textbox(
                label="Durum",
                interactive=False
            )
    
    gr.Markdown("""
    ---
    
    ### ğŸ“Š Ã–rnek GÃ¶rÃ¼ntÃ¼ler
    """)
    
    # Ã–rnek gÃ¶rÃ¼ntÃ¼ler
    gr.Examples(
        examples=[
            ["../input/PNG/Original/1.png"],
            ["../input/PNG/Original/50.png"],
            ["../input/PNG/Original/100.png"],
        ],
        inputs=input_image,
        label="Ã–rnek kolonoskopi gÃ¶rÃ¼ntÃ¼leri"
    )
    
    gr.Markdown("""
    ---
    
    **Model:** UNet++ | **Framework:** PyTorch | **Veri Seti:** CVC-Clinic Database
    
    âš ï¸ *Bu araÃ§ sadece eÄŸitim amaÃ§lÄ±dÄ±r. TÄ±bbi teÅŸhis iÃ§in kullanÄ±lamaz.*
    """)
    
    # Buton baÄŸlantÄ±sÄ±
    analyze_btn.click(
        fn=predict,
        inputs=input_image,
        outputs=[output_image, status_text]
    )


if __name__ == "__main__":
    print("ğŸš€ Gradio arayÃ¼zÃ¼ baÅŸlatÄ±lÄ±yor...")
    print("ğŸ“ TarayÄ±cÄ±da aÃ§: http://localhost:7860")
    demo.launch(
        server_name="0.0.0.0",
        server_port=7860,
        share=False
    )
